// Copyright (c) 2011-present, Facebook, Inc.  All rights reserved.
//  This source code is licensed under both the GPLv2 (found in the
//  COPYING file in the root directory) and Apache 2.0 License
//  (found in the LICENSE.Apache file in the root directory).
// Copyright (c) 2012 The LevelDB Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file. See the AUTHORS file for names of contributors.
//
// A database can be configured with a custom FilterPolicy object.
// This object is responsible for creating a small filter from a set
// of keys.  These filters are stored in rocksdb and are consulted
// automatically by rocksdb to decide whether or not to read some
// information from disk. In many cases, a filter can cut down the
// number of disk seeks form a handful to a single disk seek per
// DB::Get() call.
//
// Most people will want to use the builtin bloom filter support (see
// NewBloomFilterPolicy() below).

#pragma once

#include <stdlib.h>

#include <algorithm>
#include <memory>
#include <stdexcept>
#include <string>
#include <vector>

#include "rocksdb/status.h"
#include "rocksdb/types.h"

namespace ROCKSDB_NAMESPACE {

class Slice;

// As of RocksDB 7.0, the details of these classes are internal
// A class that takes a bunch of keys, then generates filter
class FilterBitsBuilder {
public:
    virtual ~FilterBitsBuilder() {}

    // Add a key (or prefix) to the filter. Typically, a builder will keep
    // a set of 64-bit key hashes and only build the filter in Finish
    // when the final number of keys is known. Keys are added in sorted order
    // and duplicated keys are possible, so typically, the builder will
    // only add this key if its hash is different from the most recently
    // added.
    virtual void AddKey(const Slice& key) = 0;

    // Called by RocksDB before Finish to populate
    // TableProperties::num_filter_entries, so should represent the
    // number of unique keys (and/or prefixes) added, but does not have
    // to be exact. `return 0;` may be used to conspicuously indicate "unknown".
    virtual size_t EstimateEntriesAdded() = 0;

    // Generate the filter using the keys that are added
    // The return value of this function would be the filter bits,
    // The ownership of actual data is set to buf
    virtual Slice Finish(std::unique_ptr<const char[]>* buf) = 0;

    // Similar to Finish(std::unique_ptr<const char[]>* buf), except that
    // for a non-null status pointer argument, it will point to
    // Status::Corruption() when there is any corruption during filter
    // construction or Status::OK() otherwise.
    //
    // WARNING: do not use a filter resulted from a corrupted construction
    // TODO: refactor this to have a better signature, consolidate
    virtual Slice Finish(std::unique_ptr<const char[]>* buf,
                         Status* /* status */) {
        return Finish(buf);
    }

    // Verify the filter returned from calling FilterBitsBuilder::Finish.
    // The function returns Status::Corruption() if there is any corruption in the
    // constructed filter or Status::OK() otherwise.
    //
    // Implementations should normally consult
    // FilterBuildingContext::table_options.detect_filter_construct_corruption
    // to determine whether to perform verification or to skip by returning
    // Status::OK(). The decision is left to the FilterBitsBuilder so that
    // verification prerequisites before PostVerify can be skipped when not
    // configured.
    //
    // RocksDB internal will always call MaybePostVerify() on the filter after
    // it is returned from calling FilterBitsBuilder::Finish
    // except for FilterBitsBuilder::Finish resulting a corruption
    // status, which indicates the filter is already in a corrupted state and
    // there is no need to post-verify
    virtual Status MaybePostVerify(const Slice& /* filter_content */) {
        return Status::OK();
    }

    // Approximate the number of keys that can be added and generate a filter
    // <= the specified number of bytes. Callers (including RocksDB) should
    // only use this result for optimizing performance and not as a guarantee.
    virtual size_t ApproximateNumEntries(size_t bytes) = 0;
};

// A class that checks if a key can be in filter
// It should be initialized by Slice generated by BitsBuilder
class FilterBitsReader {
public:
    virtual ~FilterBitsReader() {}

    // Check if the entry match the bits in filter
    virtual bool MayMatch(const Slice& entry) = 0;

    // Check if an array of entries match the bits in filter
    virtual void MayMatch(int num_keys, Slice** keys, bool* may_match) {
        for (int i = 0; i < num_keys; ++i) {
            may_match[i] = MayMatch(*keys[i]);
        }
    }
};


// Base class for RocksDB built-in filter reader with
// extra useful functionalities for inernal.
class BuiltinFilterBitsReader : public FilterBitsReader {
public:
    // Check if the hash of the entry match the bits in filter
    virtual bool HashMayMatch(const uint64_t /* h */) { return true; }
};

// Contextual information passed to BloomFilterPolicy at filter building time.
// Used in overriding FilterPolicy::GetBuilderWithContext(). References other
// structs because this is expected to be a temporary, stack-allocated object.
struct FilterBuildingContext {
    // This constructor is for internal use only and subject to change.
    FilterBuildingContext();


    // Number of LSM levels, or -1 if unknown
    int num_levels = -1;


    // Name of the column family for the table (or empty string if unknown)
    // TODO: consider changing to Slice
    std::string column_family_name;

    // The table level at time of constructing the SST file, or -1 if unknown
    // or N/A as in SstFileWriter. (The table file could later be used at a
    // different level.)
    int level_at_creation = -1;

    // True if known to be going into bottommost sorted run for applicable
    // key range (which might not even be last level with data). False
    // otherwise.
    bool is_bottommost = false;

    // Reason for creating the file with the filter
    TableFileCreationReason reason = TableFileCreationReason::kMisc;
};

// Determines what kind of filter (if any) to generate in SST files, and under
// which conditions. API users can create custom filter policies that
// defer to other built-in policies (see NewBloomFilterPolicy and
// NewRibbonFilterPolicy) based on the context provided to
// GetBuilderWithContext.
class FilterPolicy  {
 public:
  virtual ~FilterPolicy();
  static const char* Type() { return "FilterPolicy"; }

  // The name used for identifying whether a filter on disk is readable
  // by this FilterPolicy. If this FilterPolicy is part of a family that
  // can read each others filters, such as built-in BloomFilterPolcy and
  // RibbonFilterPolicy, the CompatibilityName is a shared family name,
  // while kinds of filters in the family can have distinct Customizable
  // Names. This function is pure virtual so that wrappers around built-in
  // policies are prompted to defer to CompatibilityName() of the wrapped
  // policy, which is important for compatibility.
  //
  // For custom filter policies that are not part of a read-compatible
  // family (rare), implementations may return Name().
  virtual const char* CompatibilityName() const = 0;

  // Return a new FilterBitsBuilder for constructing full or partitioned
  // filter blocks, or return nullptr to indicate "no filter". Custom
  // implementations should defer to a built-in FilterPolicy to get a
  // new FilterBitsBuilder, but the FilterBuildingContext can be used
  // to decide which built-in FilterPolicy to defer to.
  virtual FilterBitsBuilder* GetBuilderWithContext(
      const FilterBuildingContext&) const = 0;

  // Return a new FilterBitsReader for full or partitioned filter blocks.
  // Caller retains ownership of any buffer pointed to by the input Slice.
  // Custom implementation should defer to GetFilterBitsReader on any
  // built-in FilterPolicy, which can read filters generated by any other
  // built-in FilterPolicy.
  virtual FilterBitsReader* GetFilterBitsReader(
      const Slice& /*contents*/) const = 0;
};

// Return a new filter policy that uses a bloom filter with approximately
// the specified number of bits per key. See
// https://github.com/facebook/rocksdb/wiki/RocksDB-Bloom-Filter
//
// bits_per_key: average bits allocated per key in bloom filter. A good
// choice is 9.9, which yields a filter with ~ 1% false positive rate.
// When format_version < 5, the value will be rounded to the nearest
// integer. Recommend using no more than three decimal digits after the
// decimal point, as in 6.667.
//
// To avoid configurations that are unlikely to produce good filtering
// value for the CPU overhead, bits_per_key < 0.5 is rounded down to 0.0
// which means "generate no filter", and 0.5 <= bits_per_key < 1.0 is
// rounded up to 1.0, for a 62% FP rate.
//
// The caller is responsible for eventually deleting the result, though
// this is typically handled automatically with BlockBasedTableOptions:
//   table_options.filter_policy.reset(NewBloomFilterPolicy(...));
//
// As of RocksDB 7.0, the use_block_based_builder parameter is ignored.
// (The old, inefficient block-based filter is no longer accessible in
// the public API.)
//
// Note: if you are using a custom comparator that ignores some parts
// of the keys being compared, you must not use NewBloomFilterPolicy()
// and must provide your own FilterPolicy that also ignores the
// corresponding parts of the keys.  For example, if the comparator
// ignores trailing spaces, it would be incorrect to use a
// FilterPolicy (like NewBloomFilterPolicy) that does not ignore
// trailing spaces in keys.
extern const FilterPolicy* NewBloomFilterPolicy(
    double bits_per_key, bool IGNORED_use_block_based_builder = false);

// A new Bloom alternative that saves about 30% space compared to
// Bloom filters, with similar query times but roughly 3-4x CPU time
// and 3x temporary space usage during construction.  For example, if
// you pass in 10 for bloom_equivalent_bits_per_key, you'll get the same
// 0.95% FP rate as Bloom filter but only using about 7 bits per key.
//
// The space savings of Ribbon filters makes sense for lower (higher
// numbered; larger; longer-lived) levels of LSM, whereas the speed of
// Bloom filters make sense for highest levels of LSM. Setting
// bloom_before_level allows for this design with Level and Universal
// compaction styles. For example, bloom_before_level=1 means that Bloom
// filters will be used in level 0, including flushes, and Ribbon
// filters elsewhere, including FIFO compaction and external SST files.
// For this option, memtable flushes are considered level -1 (so that
// flushes can be distinguished from intra-L0 compaction).
// bloom_before_level=0 (default) -> Generate Bloom filters only for
// flushes under Level and Universal compaction styles.
// bloom_before_level=-1 -> Always generate Ribbon filters (except in
// some extreme or exceptional cases).
//
// Ribbon filters are compatible with RocksDB >= 6.15.0. Earlier
// versions reading the data will behave as if no filter was used
// (degraded performance until compaction rebuilds filters). All
// built-in FilterPolicies (Bloom or Ribbon) are able to read other
// kinds of built-in filters.
//
// Note: the current Ribbon filter schema uses some extra resources
// when constructing very large filters. For example, for 100 million
// keys in a single filter (one SST file without partitioned filters),
// 3GB of temporary, untracked memory is used, vs. 1GB for Bloom.
// However, the savings in filter space from just ~60 open SST files
// makes up for the additional temporary memory use.
//
// Also consider using optimize_filters_for_memory to save filter
// memory.
extern FilterBitsBuilder* CreateStandard128RibbonBitsBuilder(double bits_per_key);
extern FilterBitsBuilder* CreateFastLocalBloomBitsBuilder(double bits_per_key);
extern FilterBitsReader* GetBuiltinFilterBitsReader(const Slice& contents);

}  // namespace ROCKSDB_NAMESPACE
